{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import create_model\n",
    "from src.dataset import *\n",
    "from src.trainer import create_model_config\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# CMI Gesture Recognition - Inference Notebook\n",
    "\n",
    "This notebook demonstrates how to load and use the trained gesture recognition model for inference.\n",
    "\n",
    "## Key Updates for Simplified Architecture:\n",
    "- Uses `create_model()` function instead of direct class instantiation\n",
    "- Simplified chunk-wise processing with dataset-level chunking\n",
    "- Clean logit averaging for multi-chunk sequences\n",
    "- Compatible with focal loss + label smoothing trained models\n",
    "\n",
    "## Usage:\n",
    "1. Update the `exp_dir` path to point to your trained model directory\n",
    "2. Run all cells to load model and test inference\n",
    "3. The `predict()` function can be used with the Kaggle inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and config\n",
    "exp_dir = Path('../experiments/cmi_training_20250818_234605')  # Update this path as needed\n",
    "with open(exp_dir / 'configs' / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Create model config\n",
    "model_config = create_model_config(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    d_model=config['model']['d_model'],\n",
    "    hidden_dim=config['model']['hidden_dim'],\n",
    "    num_heads=config['model']['num_heads'],\n",
    "    num_layers=config['model']['num_layers'],\n",
    "    acc_dim=3,  # Standard accelerometer dimensions\n",
    "    rot_dim=4,  # Standard rotation dimensions  \n",
    "    thm_dim=5,  # Standard thermal dimensions\n",
    "    dropout=config['model']['dropout'],\n",
    "    max_seq_length=config['model'].get('max_seq_length', 5000),\n",
    "    sequence_processor=config['model']['sequence_processor'],\n",
    "    tof_backbone=config['model']['tof_backbone']\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = create_model(**model_config)\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load(exp_dir / 'models/best_model.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for label encoding setup\n",
    "dataset_dir = Path('../dataset')\n",
    "train_sequences_df = pl.read_csv(dataset_dir / 'train.csv')\n",
    "train_sequences_df = train_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "train_demographics_df = pl.read_csv(dataset_dir / 'train_demographics.csv')\n",
    "\n",
    "# Prepare gesture labels and get label encoder\n",
    "train_sequences_df, labelencoder, target_gesture_id, non_target_gesture_id = prepare_gesture_labels(train_sequences_df)\n",
    "\n",
    "# Get gesture classes for mapping predictions back to gesture names\n",
    "gesture_classes = list(labelencoder.classes_)\n",
    "print(f\"Loaded {len(gesture_classes)} gesture classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_chunk_average(logits):\n",
    "    for i in range(1, logits.shape[0]-1):\n",
    "        logits[i, :] = (\n",
    "            logits[i-1, :] * 0.2 + \n",
    "            logits[i, :] * 0.6 + \n",
    "            logits[i+1, :] * 0.2\n",
    "        )\n",
    "    logits[0, :] = logits[1, :] * 0.2 + logits[0, :] * 0.8\n",
    "    logits[-1, :] = logits[-2, :] * 0.2 + logits[-1, :] * 0.8\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Inference Pipeline Summary:\n",
    "# \n",
    "# Key Changes from Original:\n",
    "# 1. Uses simplified model architecture with create_model() function\n",
    "# 2. Uses dataset chunking instead of complex model chunking methods\n",
    "# 3. Simple logit averaging across chunks for final prediction\n",
    "# 4. No complex attention-based chunk aggregation needed\n",
    "# 5. Cleaner, more maintainable code structure\n",
    "# \n",
    "# Model Pipeline:\n",
    "# Sequence â†’ Dataset chunks â†’ Model forward() â†’ Average logits â†’ Prediction\n",
    "\n",
    "print(\"ðŸ”„ Updated inference pipeline for simplified architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_batch):\n",
    "    \"\"\"\n",
    "    Predict gesture for a single sequence using simplified chunk-wise processing.\n",
    "    \n",
    "    Args:\n",
    "        data_batch: Tuple of (sequence_df, demographics_df) from the inference server\n",
    "        \n",
    "    Returns:\n",
    "        str: Predicted gesture name\n",
    "    \"\"\"\n",
    "    sequence_df, demographics_df = data_batch\n",
    "    \n",
    "    # Process sequence into chunks\n",
    "    sequence_processor = SequenceProcessor()\n",
    "    sequences = sequence_processor.process_dataframe(\n",
    "        df=sequence_df, \n",
    "        chunk_size=config['data']['chunk_size']\n",
    "    )\n",
    "    \n",
    "    if not sequences:\n",
    "        return \"Text on phone\"  # Default prediction if no valid sequences\n",
    "    \n",
    "    # Create dataset for this sequence with chunking enabled\n",
    "    dataset = CMIDataset(\n",
    "        sequences=sequences, \n",
    "        chunk_size=config['data']['chunk_size'],\n",
    "        use_chunking=True,\n",
    "        augmentation_config=None  # No augmentation for inference\n",
    "    )\n",
    "    \n",
    "    # Collect predictions from all chunks\n",
    "    chunk_logits = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_data in dataset:\n",
    "            # Get chunk data\n",
    "            tof_chunk = chunk_data['tof'].unsqueeze(0).to(device)  # (1, chunk_size, 320)\n",
    "            acc_chunk = chunk_data['acc'].unsqueeze(0).to(device)  # (1, chunk_size, 3)\n",
    "            rot_chunk = chunk_data['rot'].unsqueeze(0).to(device)  # (1, chunk_size, 4)\n",
    "            thm_chunk = chunk_data['thm'].unsqueeze(0).to(device)  # (1, chunk_size, 5)\n",
    "            \n",
    "            # Simple forward pass through model\n",
    "            logits = model(tof_chunk, acc_chunk, rot_chunk, thm_chunk)  # (1, num_classes)\n",
    "            chunk_logits.append(logits.squeeze(0))  # (num_classes,)\n",
    "    \n",
    "    if not chunk_logits:\n",
    "        return \"Text on phone\"  # Default prediction\n",
    "    \n",
    "    # Average logits across all chunks (simple aggregation)\n",
    "    if len(chunk_logits) == 1:\n",
    "        final_logits = chunk_logits[0]\n",
    "    else:\n",
    "        stacked_logits = torch.stack(chunk_logits)  # (num_chunks, num_classes)\n",
    "        final_logits = stacked_logits.mean(dim=0)   # (num_classes,)\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class_id = final_logits.argmax().item()\n",
    "    \n",
    "    # Map class ID back to gesture name\n",
    "    predicted_gesture = gesture_classes[predicted_class_id]\n",
    "    \n",
    "    return predicted_gesture\n",
    "\n",
    "print(\"Predict function with simplified chunk processing defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on training data (optional evaluation)\n",
    "grouped = train_sequences_df.group_by(\"sequence_id\")\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Limit to first 10 sequences for quick testing (remove limit for full evaluation)\n",
    "for i, (sequence_id, sequence) in enumerate(tqdm(grouped)):\n",
    "    if i >= 10:  # Remove this line for full evaluation\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        # Predict gesture for this sequence\n",
    "        predicted_gesture = predict((sequence, train_demographics_df))\n",
    "        predictions.append(predicted_gesture)\n",
    "        true_labels.append(sequence['gesture'][0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sequence {sequence_id[0]}: {e}\")\n",
    "        # Skip this sequence\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(predictions)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics if we have predictions\n",
    "if predictions and true_labels:\n",
    "    from sklearn.metrics import f1_score, accuracy_score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Show some example predictions\n",
    "    print(f\"\\nExample predictions:\")\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        print(f\"  True: {true_labels[i]}\")\n",
    "        print(f\"  Pred: {predictions[i]}\")\n",
    "        print(f\"  Match: {'âœ“' if true_labels[i] == predictions[i] else 'âœ—'}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No valid predictions to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean(logits)\n",
    "# F1 Score: 0.7187\n",
    "# Accuracy: 0.7314\n",
    "\n",
    "# smooth_chunk_average(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and run the inference server\n",
    "# import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "# inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     # Running in Kaggle competition environment\n",
    "#     inference_server.serve()\n",
    "# else:\n",
    "#     # # Running locally for testing\n",
    "#     inference_server.run_local_gateway(\n",
    "#         data_paths=(\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Show results if running locally\n",
    "# if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#         results = pd.read_parquet(\"submission.parquet\")\n",
    "#         print(results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
