{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import GestureBranchedModel\n",
    "from src.dataset import *\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and config\n",
    "exp_dir = Path('../experiments/cmi_training_20250814_220701')\n",
    "with open(exp_dir / 'configs' / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Initialize model\n",
    "model = GestureBranchedModel(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    d_model=config['model']['d_model'],\n",
    "    d_reduced=config['model']['d_reduced'],\n",
    "    num_heads=config['model']['num_heads'],\n",
    "    num_layers=config['model']['num_layers'],\n",
    "    dropout=config['model']['dropout'],\n",
    "    max_seq_length=config['model']['max_seq_length'],\n",
    "    sequence_processor=config['model']['sequence_processor'],\n",
    "    tof_backbone=config['model']['tof_backbone']\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load(exp_dir / 'models/best_model.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for label encoding setup\n",
    "dataset_dir = Path('../dataset')\n",
    "train_sequences_df = pl.read_csv(dataset_dir / 'train.csv')\n",
    "train_sequences_df = train_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "\n",
    "# Prepare gesture labels and get label encoder\n",
    "train_sequences_df, labelencoder, target_gesture_id, non_target_gesture_id = prepare_gesture_labels(train_sequences_df)\n",
    "\n",
    "# Get gesture classes for mapping predictions back to gesture names\n",
    "gesture_classes = list(labelencoder.classes_)\n",
    "print(f\"Loaded {len(gesture_classes)} gesture classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_batch):\n",
    "    \"\"\"\n",
    "    Predict gesture for a single sequence.\n",
    "    \n",
    "    Args:\n",
    "        data_batch: Tuple of (sequence_df, demographics_df) from the inference server\n",
    "        \n",
    "    Returns:\n",
    "        str: Predicted gesture name\n",
    "    \"\"\"\n",
    "    sequence_df, demographics_df = data_batch\n",
    "    \n",
    "    # Process sequence into chunks\n",
    "    sequence_processor = SequenceProcessor()\n",
    "    sequences = sequence_processor.process_dataframe(\n",
    "        df=sequence_df, \n",
    "        max_seq_length=config['data']['max_seq_length']\n",
    "    )\n",
    "    \n",
    "    if not sequences:\n",
    "        return \"Text on phone\"  # Default prediction if no valid sequences\n",
    "    \n",
    "    # Create dataset for this sequence\n",
    "    dataset = CMIDataset(sequences=sequences, max_length=config['data']['max_seq_length'])\n",
    "    \n",
    "    # Collect all chunks for this sequence\n",
    "    batch_data = []\n",
    "    for data in dataset:\n",
    "        batch_data.append(data)\n",
    "    \n",
    "    if not batch_data:\n",
    "        return \"Text on phone\"  # Default prediction\n",
    "    \n",
    "    # Stack tensors for batch processing\n",
    "    tof_batch = torch.stack([d['tof'] for d in batch_data]).to(device)  # (batch_size, seq_len, 320)\n",
    "    acc_batch = torch.stack([d['acc'] for d in batch_data]).to(device)  # (batch_size, seq_len, 3)\n",
    "    rot_batch = torch.stack([d['rot'] for d in batch_data]).to(device)  # (batch_size, seq_len, 4)\n",
    "    thm_batch = torch.stack([d['thm'] for d in batch_data]).to(device)  # (batch_size, seq_len, 5)\n",
    "    chunk_start_idx_batch = torch.stack([d['chunk_start_idx'] for d in batch_data]).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            tof_features=tof_batch,\n",
    "            acc_features=acc_batch,\n",
    "            rot_features=rot_batch,\n",
    "            thm_features=thm_batch,\n",
    "            chunk_start_idx=chunk_start_idx_batch\n",
    "        )  # (batch_size, num_classes)\n",
    "    \n",
    "    # Average predictions across all chunks and get predicted class\n",
    "    mean_logits = logits.mean(dim=0)  # (num_classes,)\n",
    "    predicted_class_id = mean_logits.argmax().item()\n",
    "    \n",
    "    # Map class ID back to gesture name\n",
    "    predicted_gesture = gesture_classes[predicted_class_id]\n",
    "    \n",
    "    return predicted_gesture\n",
    "\n",
    "print(\"Predict function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the predict function with sample data\n",
    "test_sequences_df = pl.read_csv(dataset_dir / 'test.csv')\n",
    "test_sequences_df = test_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "test_demographics_df = pl.read_csv(dataset_dir / 'test_demographics.csv')\n",
    "\n",
    "# Get a sample sequence for testing\n",
    "sample_sequence_id = test_sequences_df['sequence_id'][0]\n",
    "sample_sequence = test_sequences_df.filter(pl.col('sequence_id') == sample_sequence_id)\n",
    "sample_demographics = test_demographics_df.filter(pl.col('subject') == sample_sequence['subject'][0])\n",
    "\n",
    "# Test prediction\n",
    "test_prediction = predict((sample_sequence, sample_demographics))\n",
    "print(f\"Sample prediction for sequence {sample_sequence_id}: {test_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the inference server\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Running in Kaggle competition environment\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Running locally for testing\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Show results if running locally\n",
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    try:\n",
    "        results = pd.read_parquet(\"submission.parquet\")\n",
    "        print(\"Submission results:\")\n",
    "        print(results.head())\n",
    "        print(f\"Total predictions: {len(results)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No submission.parquet file found - may need to run with proper data paths\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
