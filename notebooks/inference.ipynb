{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import GestureBranchedModel\n",
    "from src.dataset import *\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and config\n",
    "exp_dir = Path('../experiments/cmi_training_20250818_234605')\n",
    "with open(exp_dir / 'configs' / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Initialize model\n",
    "model = GestureBranchedModel(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    d_model=config['model']['d_model'],\n",
    "    d_reduced=config['model']['d_reduced'],\n",
    "    num_heads=config['model']['num_heads'],\n",
    "    num_layers=config['model']['num_layers'],\n",
    "    dropout=config['model']['dropout'],\n",
    "    max_seq_length=config['model']['max_seq_length'],\n",
    "    sequence_processor=config['model']['sequence_processor'],\n",
    "    tof_backbone=config['model']['tof_backbone']\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load(exp_dir / 'models/best_model.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for label encoding setup\n",
    "dataset_dir = Path('../dataset')\n",
    "train_sequences_df = pl.read_csv(dataset_dir / 'train.csv')\n",
    "train_sequences_df = train_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "train_demographics_df = pl.read_csv(dataset_dir / 'train_demographics.csv')\n",
    "\n",
    "# Prepare gesture labels and get label encoder\n",
    "train_sequences_df, labelencoder, target_gesture_id, non_target_gesture_id = prepare_gesture_labels(train_sequences_df)\n",
    "\n",
    "# Get gesture classes for mapping predictions back to gesture names\n",
    "gesture_classes = list(labelencoder.classes_)\n",
    "print(f\"Loaded {len(gesture_classes)} gesture classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_chunk_average(logits):\n",
    "    for i in range(1, logits.shape[0]-1):\n",
    "        logits[i, :] = (\n",
    "            logits[i-1, :] * 0.2 + \n",
    "            logits[i, :] * 0.6 + \n",
    "            logits[i+1, :] * 0.2\n",
    "        )\n",
    "    logits[0, :] = logits[1, :] * 0.2 + logits[0, :] * 0.8\n",
    "    logits[-1, :] = logits[-2, :] * 0.2 + logits[-1, :] * 0.8\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_batch):\n",
    "    \"\"\"\n",
    "    Predict gesture for a single sequence using attention-based chunk aggregation.\n",
    "    \n",
    "    Args:\n",
    "        data_batch: Tuple of (sequence_df, demographics_df) from the inference server\n",
    "        \n",
    "    Returns:\n",
    "        str: Predicted gesture name\n",
    "    \"\"\"\n",
    "    sequence_df, demographics_df = data_batch\n",
    "    \n",
    "    # Process sequence into chunks\n",
    "    sequence_processor = SequenceProcessor()\n",
    "    sequences = sequence_processor.process_dataframe(\n",
    "        df=sequence_df, \n",
    "        max_seq_length=config['data']['chunk_size']\n",
    "    )\n",
    "    \n",
    "    if not sequences:\n",
    "        return \"Text on phone\"  # Default prediction if no valid sequences\n",
    "    \n",
    "    # Create dataset for this sequence\n",
    "    dataset = CMIDataset(sequences=sequences, max_length=config['data']['chunk_size'])\n",
    "    \n",
    "    # Collect all chunks for this sequence\n",
    "    chunk_data_list = []\n",
    "    for data in dataset:\n",
    "        chunk_data_list.append({\n",
    "            'tof': data['tof'].to(device),  # (seq_len, 320)\n",
    "            'acc': data['acc'].to(device),  # (seq_len, 3)\n",
    "            'rot': data['rot'].to(device),  # (seq_len, 4)\n",
    "            'thm': data['thm'].to(device),  # (seq_len, 5)\n",
    "            'chunk_start_idx': data['chunk_start_idx'].to(device)  # scalar\n",
    "        })\n",
    "    \n",
    "    if not chunk_data_list:\n",
    "        return \"Text on phone\"  # Default prediction\n",
    "    \n",
    "    # Use attention-based chunk aggregation\n",
    "    with torch.no_grad():\n",
    "        if len(chunk_data_list) == 1:\n",
    "            # Single chunk - use regular forward pass\n",
    "            chunk = chunk_data_list[0]\n",
    "            logits = model(\n",
    "                tof_features=chunk['tof'].unsqueeze(0),  # (1, seq_len, 320)\n",
    "                acc_features=chunk['acc'].unsqueeze(0),  # (1, seq_len, 3)\n",
    "                rot_features=chunk['rot'].unsqueeze(0),  # (1, seq_len, 4)\n",
    "                thm_features=chunk['thm'].unsqueeze(0),  # (1, seq_len, 5)\n",
    "                chunk_start_idx=chunk['chunk_start_idx'].unsqueeze(0)  # (1,)\n",
    "            ).squeeze(0)  # (num_classes,)\n",
    "        else:\n",
    "            # Multiple chunks - use attention-based aggregation\n",
    "            logits, attention_weights = model.predict_with_chunks(chunk_data_list)\n",
    "            \n",
    "            # Optional: Log attention weights for debugging\n",
    "            # print(f\"Chunk attention weights: {attention_weights.cpu().numpy()}\")\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    \n",
    "    # Map class ID back to gesture name\n",
    "    predicted_gesture = gesture_classes[predicted_class_id]\n",
    "    \n",
    "    return predicted_gesture\n",
    "\n",
    "print(\"Predict function with chunk attention defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_sequences_df.group_by(\"sequence_id\")\n",
    "predictions = []\n",
    "true_labels = []\n",
    "for sequence_id, sequence in tqdm(grouped):\n",
    "    # Predict gesture for this sequence\n",
    "    predicted_gesture = predict((sequence, train_demographics_df))\n",
    "    \n",
    "    predictions.append(predicted_gesture)\n",
    "    true_labels.append(sequence['gesture'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean(logits)\n",
    "# F1 Score: 0.7187\n",
    "# Accuracy: 0.7314\n",
    "\n",
    "# smooth_chunk_average(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and run the inference server\n",
    "# import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "# inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     # Running in Kaggle competition environment\n",
    "#     inference_server.serve()\n",
    "# else:\n",
    "#     # # Running locally for testing\n",
    "#     inference_server.run_local_gateway(\n",
    "#         data_paths=(\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Show results if running locally\n",
    "# if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#         results = pd.read_parquet(\"submission.parquet\")\n",
    "#         print(results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
