{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from src.model import GestureBranchedModel\n",
    "from src.dataset import *\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(seed=0):\n",
    "    exp_dir = Path(f'../experiments/seed{seed}')\n",
    "    with open(exp_dir / 'configs' / 'config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return exp_dir, config\n",
    "\n",
    "def load_model(exp_dir, config):\n",
    "    # Initialize model\n",
    "    model = GestureBranchedModel(\n",
    "        num_classes=config['model']['num_classes'],\n",
    "        d_model=config['model']['d_model'],\n",
    "        hidden_dim=config['model']['hidden_dim'],\n",
    "        num_heads=config['model']['num_heads'],\n",
    "        num_layers=config['model']['num_layers'],\n",
    "        dropout=config['model']['dropout'],\n",
    "        sequence_processor=config['model']['sequence_processor'],\n",
    "        tof_backbone=config['model']['tof_backbone']\n",
    "    )\n",
    "\n",
    "    # Load trained weights\n",
    "    checkpoint = torch.load(exp_dir / 'models/best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for label encoding setup\n",
    "train_sequences_df = pl.read_csv('../dataset/train.csv')\n",
    "train_sequences_df = train_sequences_df.fill_null(0.0).fill_nan(0.0)\n",
    "\n",
    "# Prepare gesture labels and get label encoder\n",
    "train_sequences_df, labelencoder, target_gesture_id, non_target_gesture_id = prepare_gesture_labels(train_sequences_df)\n",
    "\n",
    "# Get gesture classes for mapping predictions back to gesture names\n",
    "gesture_classes = list(labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_prediction(logits):\n",
    "    for i in range(1, logits.shape[0]-1):\n",
    "        logits[i, :] = (\n",
    "            logits[i-1, :] * 0.2 + \n",
    "            logits[i, :] * 0.6 + \n",
    "            logits[i+1, :] * 0.2\n",
    "        )\n",
    "    logits[0, :] = logits[1, :] * 0.2 + logits[0, :] * 0.8\n",
    "    logits[-1, :] = logits[-2, :] * 0.2 + logits[-1, :] * 0.8\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chunk_valid(tof, acc, rot, thm, zero_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Check if a chunk is valid (not overwhelmed by zero values).\n",
    "    \n",
    "    Args:\n",
    "        tof, acc, rot, thm: Tensor chunks for each sensor modality\n",
    "        zero_threshold: Fraction of zero values above which chunk is considered invalid\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if chunk is valid, False if overwhelmed by zeros\n",
    "    \"\"\"\n",
    "    # Calculate zero ratio for each modality\n",
    "    tof_zeros = (tof == 0).float().mean().item()\n",
    "    acc_zeros = (acc == 0).float().mean().item()  \n",
    "    rot_zeros = (rot == 0).float().mean().item()\n",
    "    thm_zeros = (thm == 0).float().mean().item()\n",
    "    \n",
    "    # If any modality is overwhelmed by zeros, consider chunk invalid\n",
    "    if (tof_zeros > zero_threshold or \n",
    "        acc_zeros > zero_threshold or \n",
    "        rot_zeros > zero_threshold or \n",
    "        thm_zeros > zero_threshold):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def predict(sequence_df):\n",
    "    \"\"\"\n",
    "    Predict gesture from sequence, filtering out chunks overwhelmed by zero values.\n",
    "    \n",
    "    Args:\n",
    "        sequence_df: Sequence dataframe\n",
    "        zero_threshold: Fraction of zeros above which to filter out chunk\n",
    "        min_valid_chunks: Minimum number of valid chunks required for prediction\n",
    "    \"\"\"\n",
    "    # Process sequence into chunks\n",
    "    sequence_processor = SequenceProcessor()\n",
    "    sequences = sequence_processor.process_dataframe(\n",
    "        df=sequence_df, \n",
    "        chunk_size=30\n",
    "    )\n",
    "    \n",
    "    # Create dataset for this sequence with chunking enabled\n",
    "    dataset = CMIDataset(\n",
    "        sequences=sequences, \n",
    "        chunk_size=30,\n",
    "        use_chunking=True,\n",
    "    )\n",
    "\n",
    "    # Filter valid chunks before batching\n",
    "    valid_chunks = []\n",
    "    for d in dataset:\n",
    "        if is_chunk_valid(d['tof'], d['acc'], d['rot'], d['thm'], 0.5):\n",
    "            valid_chunks.append(d)\n",
    "    \n",
    "    # Check if we have enough valid chunks\n",
    "    if len(valid_chunks) < 1:\n",
    "        # print(f\"Warning: Only {len(valid_chunks)} valid chunks found (threshold: {zero_threshold}), using all chunks\")\n",
    "        valid_chunks = list(dataset)\n",
    "    \n",
    "    # Stack tensors for batch processing\n",
    "    tof_batch = torch.stack([d['tof'] for d in valid_chunks]).to(device)  # (batch_size, seq_len, 320)\n",
    "    acc_batch = torch.stack([d['acc'] for d in valid_chunks]).to(device)  # (batch_size, seq_len, 3)\n",
    "    rot_batch = torch.stack([d['rot'] for d in valid_chunks]).to(device)  # (batch_size, seq_len, 4)\n",
    "    thm_batch = torch.stack([d['thm'] for d in valid_chunks]).to(device)  # (batch_size, seq_len, 5)\n",
    "    \n",
    "    model_logits = []\n",
    "    for i in range(3):\n",
    "        exp_dir, config = load_config(i)\n",
    "        model = load_model(exp_dir, config)\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            logits = model(\n",
    "                tof_features=tof_batch,\n",
    "                acc_features=acc_batch,\n",
    "                rot_features=rot_batch,\n",
    "                thm_features=thm_batch,\n",
    "            )  # (batch_size, num_classes)\n",
    "        \n",
    "        # Average predictions across all valid chunks and get predicted class\n",
    "        #logits = smooth_prediction(logits)\n",
    "        mean_logits = logits.mean(dim=0)  # (num_classes,)\n",
    "        model_logits.append(mean_logits.cpu().numpy())\n",
    "    \n",
    "    predicted_class_id = np.argmax(np.mean(model_logits, axis=0))\n",
    "    # Map class ID back to gesture name\n",
    "    predicted_gesture = gesture_classes[predicted_class_id]\n",
    "    return predicted_gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_labels = []\n",
    "for i, (_, group) in enumerate(train_sequences_df.group_by('sequence_id')):\n",
    "    if i > 100:\n",
    "        break\n",
    "    sequence_id = group['sequence_id'][0]\n",
    "    pred = predict(group)\n",
    "    predictions.append(pred)\n",
    "    true_labels.append(group['gesture'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "accuracy = correct / len(true_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 8095553,
     "sourceId": 12927651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
