{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import GestureBranchedModel\n",
    "from src.dataset import *\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = Path('../experiments/cmi_training_20250814_220701')\n",
    "dataset_dir = Path('../dataset')\n",
    "train_sequences_df = pl.read_csv(dataset_dir / 'train.csv')\n",
    "train_sequences_df = train_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "train_demographics_df = pl.read_csv(dataset_dir / 'train_demographics.csv')\n",
    "test_sequences_df = pl.read_csv(dataset_dir / 'test.csv')\n",
    "test_sequences_df = test_sequences_df.fill_null(-1.0).fill_nan(-1.0)\n",
    "test_demographics_df = pl.read_csv(dataset_dir / 'test_demographics.csv')\n",
    "with open(exp_dir / 'configs' / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences_df, labelencoder, target_gesture_id, non_target_gesture_id \\\n",
    "=  prepare_gesture_labels(train_sequences_df)\n",
    "# test_sequences_df['gesture_id'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from chunks\n",
    "sequence_processor = SequenceProcessor()\n",
    "train_sequences = sequence_processor.process_dataframe(\n",
    "    df=train_sequences_df, max_seq_length=config['data']['max_seq_length']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CMIDataset(\n",
    "    sequences=train_sequences,\n",
    "    max_length=config['data']['max_seq_length']\n",
    ")\n",
    "\n",
    "model = GestureBranchedModel(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    d_model= config['model']['d_model'],\n",
    "    d_reduced= config['model']['d_reduced'],\n",
    "    num_heads= config['model']['num_heads'],\n",
    "    num_layers= config['model']['num_layers'],\n",
    "    dropout= config['model']['dropout'],\n",
    "    max_seq_length= config['model']['max_seq_length'],\n",
    "    sequence_processor= config['model']['sequence_processor'],\n",
    "    tof_backbone='b0'\n",
    ")\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(exp_dir / 'models/best_model.pt', map_location='cpu')\n",
    "\n",
    "# Extract just the model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_id = dataset[0]['sequence_id']\n",
    "predictions = {}\n",
    "batch_data = []\n",
    "\n",
    "for i, data in tqdm(enumerate(dataset), total=len(dataset), desc=\"Processing sequences\"):\n",
    "    if data['sequence_id'] == processing_id:\n",
    "        # Collect data for the same sequence_id\n",
    "        batch_data.append(data)\n",
    "    else:\n",
    "        # Process the accumulated batch\n",
    "        if batch_data:\n",
    "            # Stack tensors along batch dimension\n",
    "            tof_batch = torch.stack([d['tof'] for d in batch_data]).to(device)\n",
    "            acc_batch = torch.stack([d['acc'] for d in batch_data]).to(device)\n",
    "            rot_batch = torch.stack([d['rot'] for d in batch_data]).to(device)\n",
    "            thm_batch = torch.stack([d['thm'] for d in batch_data]).to(device)\n",
    "            chunk_start_idx_batch = torch.stack([d['chunk_start_idx'] for d in batch_data]).to(device)\n",
    "            \n",
    "            # Forward pass with batched data\n",
    "            with torch.no_grad():\n",
    "                logits = model.forward(\n",
    "                    tof_features=tof_batch,\n",
    "                    acc_features=acc_batch,\n",
    "                    rot_features=rot_batch,\n",
    "                    thm_features=thm_batch,\n",
    "                    chunk_start_idx=chunk_start_idx_batch\n",
    "                )\n",
    "            \n",
    "            # Compute mean across batch dimension and get predicted class\n",
    "            mean_logits = logits.mean(dim=0)  # Average across batch\n",
    "            predicted_class = mean_logits.argmax().item()\n",
    "            \n",
    "            predictions[processing_id] = predicted_class\n",
    "        \n",
    "        # Start new sequence\n",
    "        batch_data = [data]\n",
    "        processing_id = data['sequence_id']\n",
    "\n",
    "# Process the last batch\n",
    "if batch_data:\n",
    "    tof_batch = torch.stack([d['tof'] for d in batch_data]).to(device)\n",
    "    acc_batch = torch.stack([d['acc'] for d in batch_data]).to(device)\n",
    "    rot_batch = torch.stack([d['rot'] for d in batch_data]).to(device)\n",
    "    thm_batch = torch.stack([d['thm'] for d in batch_data]).to(device)\n",
    "    chunk_start_idx_batch = torch.stack([d['chunk_start_idx'] for d in batch_data]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(\n",
    "            tof_features=tof_batch,\n",
    "            acc_features=acc_batch,\n",
    "            rot_features=rot_batch,\n",
    "            thm_features=thm_batch,\n",
    "            chunk_start_idx=chunk_start_idx_batch\n",
    "        )\n",
    "    \n",
    "    mean_logits = logits.mean(dim=0)\n",
    "    predicted_class = mean_logits.argmax().item()\n",
    "    predictions[processing_id] = predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Get true labels for evaluation\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for sequence_id in tqdm(predictions.keys()):\n",
    "    # Get true label for this sequence\n",
    "    true_label = train_sequences_df.filter(pl.col('sequence_id') == sequence_id)['gesture_id'][0]\n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(predictions[sequence_id])\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "f1_weighted = f1_score(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
