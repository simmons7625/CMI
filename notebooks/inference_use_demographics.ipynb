{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CMI Gesture Recognition - Demographic-Enhanced Inference\n",
    "\n",
    "This notebook demonstrates inference using demographic features through LightGBM and gesture embeddings from the branched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from src.dataset import CMIDataset, SequenceProcessor, prepare_gesture_labels\n",
    "from src.model import create_model\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"LightGBM version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open(project_root / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Model d_model: {config['model']['d_model']}\")\n",
    "print(f\"- Model layers: {config['model']['num_layers']}\")\n",
    "print(f\"- Max sequence length for chunking: {config['data']['max_seq_length']}\")\n",
    "print(f\"- Max sequence length for positional encoding: {config['model']['max_seq_length']}\")\n",
    "\n",
    "# Find the best trained model\n",
    "experiment_dirs = list((project_root / 'experiments').glob('cmi_training_*'))\n",
    "if not experiment_dirs:\n",
    "    raise FileNotFoundError(\"No training experiments found\")\n",
    "\n",
    "# Use the most recent experiment\n",
    "latest_experiment = max(experiment_dirs, key=lambda x: x.name)\n",
    "model_path = latest_experiment / 'models' / 'best_model.pt'\n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# Load the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Create model with saved configuration\n",
    "model_config = checkpoint['model_config']\n",
    "gesture_model = create_model(**model_config).to(device)\n",
    "gesture_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "gesture_model.eval()\n",
    "\n",
    "print(f\"Gesture model loaded successfully on {device}\")\n",
    "print(f\"Model config: {model_config}\")\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = checkpoint.get('label_encoder')\n",
    "if label_encoder is None:\n",
    "    print(\"Warning: No label encoder found in checkpoint\")\n",
    "    # Load from training data as fallback\n",
    "    train_df = pl.read_csv(project_root / 'dataset' / 'train.csv')\n",
    "    train_df, label_encoder, _, _ = prepare_gesture_labels(train_df)\n",
    "    print(f\"Label encoder loaded from training data with {len(label_encoder.classes_)} classes\")\n",
    "else:\n",
    "    print(f\"Label encoder loaded with {len(label_encoder.classes_)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Extract Gesture Embeddings from Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureEmbeddingExtractor:\n",
    "    \"\"\"Extract embeddings from the gesture branch model before classification layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, gesture_model, device):\n",
    "        self.gesture_model = gesture_model\n",
    "        self.device = device\n",
    "        self.sequence_processor = SequenceProcessor()\n",
    "        \n",
    "    def extract_embedding(self, sequence):\n",
    "        \"\"\"Extract embedding from a single sequence.\"\"\"\n",
    "        try:\n",
    "            # Process sequence into chunks\n",
    "            chunks = self._process_sequence_for_inference(sequence)\n",
    "            \n",
    "            # Create dataset from chunks\n",
    "            dataset = CMIDataset(\n",
    "                chunks,\n",
    "                max_length=config['data']['max_seq_length']\n",
    "            )\n",
    "            \n",
    "            # Create dataloader\n",
    "            dataloader = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=len(chunks),  # Process all chunks at once\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # Extract embeddings\n",
    "            all_embeddings = []\n",
    "            \n",
    "            self.gesture_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch in dataloader:\n",
    "                    # Move to device\n",
    "                    tof_data = batch[\"tof\"].to(self.device)\n",
    "                    acc_data = batch[\"acc\"].to(self.device)\n",
    "                    rot_data = batch[\"rot\"].to(self.device)\n",
    "                    thm_data = batch[\"thm\"].to(self.device)\n",
    "                    chunk_start_idx = batch.get(\"chunk_start_idx\")\n",
    "                    if chunk_start_idx is not None:\n",
    "                        chunk_start_idx = chunk_start_idx.to(self.device)\n",
    "                    \n",
    "                    # Extract embeddings before classification layer\n",
    "                    embedding = self._extract_embedding_from_model(\n",
    "                        tof_data, acc_data, rot_data, thm_data, chunk_start_idx\n",
    "                    )\n",
    "                    \n",
    "                    all_embeddings.extend(embedding.cpu().numpy())\n",
    "            \n",
    "            # Aggregate embeddings across chunks (average)\n",
    "            if len(all_embeddings) > 1:\n",
    "                avg_embedding = np.mean(all_embeddings, axis=0)\n",
    "            else:\n",
    "                avg_embedding = all_embeddings[0]\n",
    "            \n",
    "            return avg_embedding\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting embedding: {e}\")\n",
    "            # Return zero embedding as fallback\n",
    "            return np.zeros(self.gesture_model.d_model)\n",
    "    \n",
    "    def _extract_embedding_from_model(self, tof_data, acc_data, rot_data, thm_data, chunk_start_idx):\n",
    "        \"\"\"Extract embedding from model just before classification layer.\"\"\"\n",
    "        # Step 1: Process each sensor branch\n",
    "        tof_out = self.gesture_model.tof_branch(tof_data)  # (batch_size, d_model, seq_len)\n",
    "        acc_out = self.gesture_model.acc_branch(acc_data)  # (batch_size, d_model, seq_len)\n",
    "        rot_out = self.gesture_model.rot_branch(rot_data)  # (batch_size, d_model, seq_len)\n",
    "        thm_out = self.gesture_model.thm_branch(thm_data)  # (batch_size, d_model, seq_len)\n",
    "\n",
    "        # Step 2: Concatenate all sensor features\n",
    "        fused = torch.cat(\n",
    "            (tof_out, acc_out, rot_out, thm_out),\n",
    "            dim=1,\n",
    "        )  # (batch_size, 4*d_model, seq_len)\n",
    "\n",
    "        # Apply normalization\n",
    "        fused = self.gesture_model.fusion_norm(fused)\n",
    "\n",
    "        # Step 3: Transpose for transformer input (batch_size, seq_len, 4*d_model)\n",
    "        fused = fused.transpose(1, 2)\n",
    "\n",
    "        # Step 4: Apply feature selection transformer\n",
    "        transformed = self.gesture_model.feature_transformer(\n",
    "            fused,\n",
    "            chunk_start_idx,\n",
    "        )  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Step 5: Global pooling over sequence dimension\n",
    "        pooled = self.gesture_model.global_pool(transformed.transpose(1, 2)).squeeze(\n",
    "            -1,\n",
    "        )  # (batch_size, d_model)\n",
    "        \n",
    "        # Return the embedding (before classification layer)\n",
    "        return pooled\n",
    "    \n",
    "    def _process_sequence_for_inference(self, sequence):\n",
    "        \"\"\"Process a single sequence for inference.\"\"\"\n",
    "        if isinstance(sequence, pl.DataFrame):\n",
    "            sequence_id = sequence['sequence_id'][0]\n",
    "        else:\n",
    "            sequence_id = sequence['sequence_id'].iloc[0]\n",
    "        \n",
    "        try:\n",
    "            # Create enhanced features using FeatureProcessor\n",
    "            enhanced_features = self.sequence_processor.feature_processor.create_sequence_features(sequence)\n",
    "            \n",
    "            # Apply chunking\n",
    "            chunks = self.sequence_processor._chunk_sequence(\n",
    "                enhanced_features,\n",
    "                0,  # dummy gesture_id for inference\n",
    "                sequence_id,\n",
    "                config['data']['max_seq_length'],\n",
    "            )\n",
    "            \n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing enhanced features: {e}\")\n",
    "            # Fallback to original processing\n",
    "            return self._fallback_sequence_processing(sequence, sequence_id)\n",
    "    \n",
    "    def _fallback_sequence_processing(self, sequence, sequence_id):\n",
    "        \"\"\"Fallback sequence processing using basic features.\"\"\"\n",
    "        # Define feature columns\n",
    "        acc_cols = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "        rot_cols = [\"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "        thm_cols = [f\"thm_{i}\" for i in range(1, 6)]\n",
    "        tof_cols = [f\"tof_{i}_v{j}\" for i in range(1, 6) for j in range(64)]\n",
    "        \n",
    "        if isinstance(sequence, pl.DataFrame):\n",
    "            seq_data = sequence.select(acc_cols + rot_cols + thm_cols + tof_cols).to_numpy()\n",
    "        else:\n",
    "            seq_data = sequence[acc_cols + rot_cols + thm_cols + tof_cols].values\n",
    "        \n",
    "        # Create basic sequence dictionary\n",
    "        return [{\n",
    "            \"sequence_id\": sequence_id,\n",
    "            \"data\": seq_data,\n",
    "            \"label\": 0  # Dummy label for inference\n",
    "        }]\n",
    "\n",
    "# Initialize embedding extractor\n",
    "embedding_extractor = GestureEmbeddingExtractor(gesture_model, device)\n",
    "print(\"Gesture embedding extractor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Prepare Demographic Features and Train LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_demographic_features(demographics_df):\n",
    "    \"\"\"Prepare and encode demographic features.\"\"\"\n",
    "    if demographics_df is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to pandas if needed\n",
    "    if isinstance(demographics_df, pl.DataFrame):\n",
    "        demo_df = demographics_df.to_pandas()\n",
    "    else:\n",
    "        demo_df = demographics_df.copy()\n",
    "    \n",
    "    # Create demographic feature encoders\n",
    "    categorical_encoders = {}\n",
    "    numerical_features = []\n",
    "    \n",
    "    # Identify feature types\n",
    "    for col in demo_df.columns:\n",
    "        if col == 'participant_id':\n",
    "            continue  # Skip ID column\n",
    "        \n",
    "        if demo_df[col].dtype in ['object', 'category']:\n",
    "            # Categorical feature - use label encoding\n",
    "            encoder = LabelEncoder()\n",
    "            demo_df[f'{col}_encoded'] = encoder.fit_transform(demo_df[col].fillna('unknown'))\n",
    "            categorical_encoders[col] = encoder\n",
    "            numerical_features.append(f'{col}_encoded')\n",
    "        else:\n",
    "            # Numerical feature\n",
    "            demo_df[col] = demo_df[col].fillna(demo_df[col].median())\n",
    "            numerical_features.append(col)\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    feature_matrix = scaler.fit_transform(demo_df[numerical_features])\n",
    "    \n",
    "    return {\n",
    "        'features': feature_matrix,\n",
    "        'feature_names': numerical_features,\n",
    "        'categorical_encoders': categorical_encoders,\n",
    "        'scaler': scaler,\n",
    "        'demo_df': demo_df\n",
    "    }, demo_df[numerical_features]\n",
    "\n",
    "def encode_demographics_for_inference(demographics_row, demo_preprocessor):\n",
    "    \"\"\"Encode demographics for a single participant during inference.\"\"\"\n",
    "    if demo_preprocessor is None or demographics_row is None:\n",
    "        return np.zeros(10)  # Return default features if no demographics\n",
    "    \n",
    "    try:\n",
    "        # Convert to dict if needed\n",
    "        if hasattr(demographics_row, 'to_dict'):\n",
    "            demo_dict = demographics_row.to_dict()\n",
    "        else:\n",
    "            demo_dict = demographics_row\n",
    "        \n",
    "        # Prepare feature vector\n",
    "        feature_vector = []\n",
    "        \n",
    "        for feature_name in demo_preprocessor['feature_names']:\n",
    "            original_col = feature_name.replace('_encoded', '')\n",
    "            \n",
    "            if feature_name.endswith('_encoded'):\n",
    "                # Categorical feature\n",
    "                encoder = demo_preprocessor['categorical_encoders'][original_col]\n",
    "                value = demo_dict.get(original_col, 'unknown')\n",
    "                try:\n",
    "                    encoded_value = encoder.transform([str(value)])[0]\n",
    "                except ValueError:\n",
    "                    # Handle unseen categories\n",
    "                    encoded_value = encoder.transform(['unknown'])[0]\n",
    "                feature_vector.append(encoded_value)\n",
    "            else:\n",
    "                # Numerical feature\n",
    "                value = demo_dict.get(original_col, demo_preprocessor['demo_df'][original_col].median())\n",
    "                feature_vector.append(value)\n",
    "        \n",
    "        # Scale features\n",
    "        feature_vector = np.array(feature_vector).reshape(1, -1)\n",
    "        scaled_features = demo_preprocessor['scaler'].transform(feature_vector)\n",
    "        \n",
    "        return scaled_features.flatten()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding demographics: {e}\")\n",
    "        return np.zeros(len(demo_preprocessor['feature_names']))\n",
    "\n",
    "# Load and prepare training data for LightGBM\n",
    "print(\"Loading training data for LightGBM training...\")\n",
    "\n",
    "try:\n",
    "    # Load training data\n",
    "    train_df = pl.read_csv(project_root / 'dataset' / 'train.csv')\n",
    "    train_demographics = pl.read_csv(project_root / 'dataset' / 'train_demographics.csv')\n",
    "    \n",
    "    # Prepare gesture labels\n",
    "    train_df, train_label_encoder, _, _ = prepare_gesture_labels(train_df)\n",
    "    \n",
    "    # Prepare demographic features\n",
    "    demo_preprocessor, demo_features = prepare_demographic_features(train_demographics)\n",
    "    \n",
    "    print(f\"Demographic features shape: {demo_features.shape if demo_features is not None else 'None'}\")\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    demo_preprocessor = None\n",
    "    print(\"Continuing without demographic preprocessing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Train LightGBM on Combined Features (Optional Training Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm_classifier(train_df, train_demographics, demo_preprocessor, embedding_extractor, num_samples=500):\n",
    "    \"\"\"Train LightGBM classifier on combined gesture embeddings and demographic features.\"\"\"\n",
    "    \n",
    "    print(f\"Training LightGBM on {num_samples} samples...\")\n",
    "    \n",
    "    # Extract features for training\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Get unique sequences (limit for training efficiency)\n",
    "    unique_sequences = train_df['sequence_id'].unique()[:num_samples]\n",
    "    \n",
    "    for i, seq_id in enumerate(unique_sequences):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Processing sequence {i+1}/{len(unique_sequences)}...\")\n",
    "        \n",
    "        try:\n",
    "            # Get sequence data\n",
    "            sequence_data = train_df.filter(pl.col('sequence_id') == seq_id)\n",
    "            \n",
    "            # Extract gesture embedding\n",
    "            gesture_embedding = embedding_extractor.extract_embedding(sequence_data)\n",
    "            \n",
    "            # Get participant demographics\n",
    "            if 'participant_id' in sequence_data.columns:\n",
    "                participant_id = sequence_data['participant_id'][0]\n",
    "                demo_row = train_demographics.filter(pl.col('participant_id') == participant_id)\n",
    "                if len(demo_row) > 0:\n",
    "                    demo_features = encode_demographics_for_inference(demo_row.to_pandas().iloc[0], demo_preprocessor)\n",
    "                else:\n",
    "                    demo_features = np.zeros(len(demo_preprocessor['feature_names'])) if demo_preprocessor else np.zeros(10)\n",
    "            else:\n",
    "                demo_features = np.zeros(len(demo_preprocessor['feature_names'])) if demo_preprocessor else np.zeros(10)\n",
    "            \n",
    "            # Combine features\n",
    "            combined_features = np.concatenate([gesture_embedding, demo_features])\n",
    "            features_list.append(combined_features)\n",
    "            \n",
    "            # Get label\n",
    "            label = sequence_data['gesture_id'][0]\n",
    "            labels_list.append(label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sequence {seq_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(features_list) == 0:\n",
    "        print(\"No features extracted for training\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to arrays\n",
    "    X = np.array(features_list)\n",
    "    y = np.array(labels_list)\n",
    "    \n",
    "    print(f\"Training features shape: {X.shape}\")\n",
    "    print(f\"Training labels shape: {y.shape}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Train LightGBM\n",
    "    lgb_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(np.unique(y)),\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "    \n",
    "    # Train model\n",
    "    lgb_model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_dataset,\n",
    "        valid_sets=[val_dataset],\n",
    "        num_boost_round=100,\n",
    "        callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_preds = lgb_model.predict(X_val)\n",
    "    val_preds_class = np.argmax(val_preds, axis=1)\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(classification_report(y_val, val_preds_class, target_names=[f'Class_{i}' for i in range(len(np.unique(y)))]))\n",
    "    \n",
    "    return lgb_model\n",
    "\n",
    "# Train LightGBM (optional - can be skipped if pre-trained model exists)\n",
    "lgb_model_path = project_root / 'models' / 'lightgbm_demographic_model.pkl'\n",
    "\n",
    "if lgb_model_path.exists():\n",
    "    print(\"Loading pre-trained LightGBM model...\")\n",
    "    with open(lgb_model_path, 'rb') as f:\n",
    "        lgb_model = pickle.load(f)\n",
    "    print(\"LightGBM model loaded successfully\")\n",
    "else:\n",
    "    if demo_preprocessor is not None:\n",
    "        print(\"Training new LightGBM model...\")\n",
    "        lgb_model = train_lightgbm_classifier(\n",
    "            train_df, train_demographics, demo_preprocessor, embedding_extractor, num_samples=200\n",
    "        )\n",
    "        \n",
    "        if lgb_model is not None:\n",
    "            # Save model\n",
    "            lgb_model_path.parent.mkdir(exist_ok=True)\n",
    "            with open(lgb_model_path, 'wb') as f:\n",
    "                pickle.dump(lgb_model, f)\n",
    "            print(f\"LightGBM model saved to {lgb_model_path}\")\n",
    "    else:\n",
    "        print(\"Cannot train LightGBM without demographic preprocessor\")\n",
    "        lgb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Demographic-Enhanced Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_demographics(sequence: pl.DataFrame, demographics: pl.DataFrame = None) -> str:\n",
    "    \"\"\"\n",
    "    Predict gesture using combined gesture embeddings and demographic features.\n",
    "    \n",
    "    Args:\n",
    "        sequence: Polars DataFrame containing sensor data for one sequence\n",
    "        demographics: Optional demographics data\n",
    "        \n",
    "    Returns:\n",
    "        String containing the predicted gesture name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract gesture embedding\n",
    "        gesture_embedding = embedding_extractor.extract_embedding(sequence)\n",
    "        \n",
    "        # Extract demographic features\n",
    "        if demographics is not None and demo_preprocessor is not None:\n",
    "            # Get participant demographics\n",
    "            if 'participant_id' in sequence.columns:\n",
    "                participant_id = sequence['participant_id'][0]\n",
    "                demo_row = demographics.filter(pl.col('participant_id') == participant_id)\n",
    "                if len(demo_row) > 0:\n",
    "                    demo_features = encode_demographics_for_inference(\n",
    "                        demo_row.to_pandas().iloc[0], demo_preprocessor\n",
    "                    )\n",
    "                else:\n",
    "                    demo_features = np.zeros(len(demo_preprocessor['feature_names']))\n",
    "            else:\n",
    "                demo_features = np.zeros(len(demo_preprocessor['feature_names']))\n",
    "        else:\n",
    "            demo_features = np.zeros(10)  # Default demographic features\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([gesture_embedding, demo_features]).reshape(1, -1)\n",
    "        \n",
    "        # Make prediction using LightGBM if available\n",
    "        if lgb_model is not None:\n",
    "            lgb_prediction = lgb_model.predict(combined_features)\n",
    "            predicted_class = np.argmax(lgb_prediction[0])\n",
    "            \n",
    "            # Convert to gesture name\n",
    "            gesture_name = label_encoder.inverse_transform([predicted_class])[0]\n",
    "            return gesture_name\n",
    "        else:\n",
    "            # Fallback to original gesture model prediction\n",
    "            print(\"LightGBM model not available, using fallback prediction\")\n",
    "            return fallback_gesture_prediction(sequence)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in demographic-enhanced prediction: {e}\")\n",
    "        return fallback_gesture_prediction(sequence)\n",
    "\n",
    "def fallback_gesture_prediction(sequence):\n",
    "    \"\"\"Fallback to original gesture model prediction.\"\"\"\n",
    "    try:\n",
    "        # Convert to pandas if needed\n",
    "        if isinstance(sequence, pl.DataFrame):\n",
    "            sequence_data = sequence.to_pandas()\n",
    "        else:\n",
    "            sequence_data = sequence\n",
    "        \n",
    "        # Process sequence into chunks\n",
    "        chunks = embedding_extractor._process_sequence_for_inference(sequence)\n",
    "        \n",
    "        # Create dataset from chunks\n",
    "        dataset = CMIDataset(\n",
    "            chunks,\n",
    "            max_length=config['data']['max_seq_length']\n",
    "        )\n",
    "        \n",
    "        # Create dataloader\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=len(chunks),\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Run inference\n",
    "        all_probabilities = []\n",
    "        \n",
    "        gesture_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Move to device\n",
    "                tof_data = batch[\"tof\"].to(device)\n",
    "                acc_data = batch[\"acc\"].to(device)\n",
    "                rot_data = batch[\"rot\"].to(device)\n",
    "                thm_data = batch[\"thm\"].to(device)\n",
    "                chunk_start_idx = batch.get(\"chunk_start_idx\")\n",
    "                if chunk_start_idx is not None:\n",
    "                    chunk_start_idx = chunk_start_idx.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = gesture_model(\n",
    "                    tof_data, acc_data, rot_data, thm_data, chunk_start_idx\n",
    "                )\n",
    "                \n",
    "                # Get probabilities\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "        \n",
    "        # Aggregate predictions across chunks\n",
    "        if len(all_probabilities) > 1:\n",
    "            avg_probabilities = np.mean(all_probabilities, axis=0)\n",
    "        else:\n",
    "            avg_probabilities = all_probabilities[0]\n",
    "        \n",
    "        # Get final prediction\n",
    "        final_prediction = np.argmax(avg_probabilities)\n",
    "        \n",
    "        # Convert to gesture name\n",
    "        gesture_name = label_encoder.inverse_transform([final_prediction])[0]\n",
    "        return gesture_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in fallback prediction: {e}\")\n",
    "        return \"Text on phone\"  # Default gesture\n",
    "\n",
    "print(\"Demographic-enhanced prediction function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Inference Server Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CMI inference server\n",
    "try:\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    \n",
    "    # Create inference server with our demographic-enhanced predict function\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict_with_demographics)\n",
    "    \n",
    "    print(\"Demographic-enhanced inference server created successfully\")\n",
    "    print(\"Available methods:\")\n",
    "    print(\"- inference_server.serve(): Start the server for competition environment\")\n",
    "    print(\"- inference_server.run_local_gateway(): Run local testing\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"kaggle_evaluation not available: {e}\")\n",
    "    print(\"This is expected when running outside Kaggle environment\")\n",
    "    print(\"You can still test the predict_with_demographics function directly\")\n",
    "    \n",
    "    # Create a mock server for local testing\n",
    "    class MockInferenceServer:\n",
    "        def __init__(self, predict_fn):\n",
    "            self.predict_fn = predict_fn\n",
    "            \n",
    "        def serve(self):\n",
    "            print(\"Mock server: serve() called\")\n",
    "            \n",
    "        def run_local_gateway(self, data_paths=None):\n",
    "            print(\"Mock server: run_local_gateway() called\")\n",
    "            if data_paths:\n",
    "                print(f\"Data paths: {data_paths}\")\n",
    "                # Load test data and run predictions\n",
    "                self.test_predictions(data_paths)\n",
    "                \n",
    "        def test_predictions(self, data_paths):\n",
    "            \"\"\"Test predictions on provided data.\"\"\"\n",
    "            try:\n",
    "                test_csv, demographics_csv = data_paths\n",
    "                \n",
    "                # Load test data\n",
    "                test_df = pl.read_csv(test_csv)\n",
    "                \n",
    "                if os.path.exists(demographics_csv):\n",
    "                    demographics_df = pl.read_csv(demographics_csv)\n",
    "                else:\n",
    "                    demographics_df = None\n",
    "                \n",
    "                print(f\"Loaded test data: {test_df.shape}\")\n",
    "                print(f\"Loaded demographics: {demographics_df.shape if demographics_df is not None else 'None'}\")\n",
    "                \n",
    "                # Test on a few sequences\n",
    "                unique_sequences = test_df['sequence_id'].unique()[:3]  # Test first 3 sequences\n",
    "                \n",
    "                for seq_id in unique_sequences:\n",
    "                    sequence_data = test_df.filter(pl.col('sequence_id') == seq_id)\n",
    "                    prediction = self.predict_fn(sequence_data, demographics_df)\n",
    "                    print(f\"Sequence {seq_id}: {prediction}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in test predictions: {e}\")\n",
    "    \n",
    "    inference_server = MockInferenceServer(predict_with_demographics)\n",
    "\n",
    "print(\"Demographic-enhanced inference server setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Run Inference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in competition environment or locally\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    print(\"Running in competition environment - starting demographic-enhanced inference server\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    print(\"Running locally - testing demographic-enhanced inference server\")\n",
    "    \n",
    "    # Define data paths for local testing\n",
    "    test_data_path = project_root / 'dataset' / 'test.csv'\n",
    "    demographics_path = project_root / 'dataset' / 'test_demographics.csv'\n",
    "    \n",
    "    if test_data_path.exists():\n",
    "        data_paths = (str(test_data_path), str(demographics_path))\n",
    "        inference_server.run_local_gateway(data_paths=data_paths)\n",
    "    else:\n",
    "        print(f\"Test data not found at {test_data_path}\")\n",
    "        print(\"Please provide the correct path to test data files\")\n",
    "        \n",
    "        # Example of direct function testing\n",
    "        print(\"\\nExample: Testing predict_with_demographics function directly...\")\n",
    "        print(\"You can call: predict_with_demographics(sequence_dataframe, demographics_dataframe)\")\n",
    "        print(\"Where sequence_dataframe contains sensor data for one sequence\")\n",
    "        print(\"And demographics_dataframe contains participant demographic information\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
